# Acceptance Criteria

This document outlines the complete set of criteria for the CourseLLM Platform. It is divided into two parts:

1.  **Release Criteria & KPIs:** The high-level metrics and checklist to determine if the product is ready for its MVP release.
2.  **Detailed Feature Criteria:** The specific, testable GIVEN/WHEN/THEN criteria for each feature.

A feature is considered "done" only when its detailed criteria are met, and the product is "ready for release" only when all release criteria are met.

---

## 1. Release Criteria & KPIs (Go/No-Go Checklist)

This is the high-level checklist to be reviewed for a "Go/No-Go" release decision.

### 1.1. Functional & Feature Criteria
These criteria ensure the core user value proposition is met.

| Persona | Feature | Acceptance Criteria |
| :--- | :--- | :--- |
| **Teacher** | Content Management | Can successfully upload, `Index`, and delete `SourceMaterial` (PDF, .md). |
| **Teacher** | Content Management | Can successfully add and remove whitelisted external URLs. |
| **Teacher** | Course Management | Can successfully define and reorder `Topic`s within a `LearningTrajectory`. |
| **Student** | Chatbot | Can hold a conversation that is verifiably grounded in the `SourceMaterial`. |
| **Student** | Chatbot | Can receive `SocraticLearning` guidance (guiding questions) for conceptual queries. |
| **Student** | Motivation | Can successfully ask "why" a topic is important and receive a relevant answer. |
| **Student** | Assessment | Can successfully generate a practice quiz based on one or more `Topic`(s). |
| **Student** | Assessment | Can submit a quiz and receive immediate, correct feedback with `Citations`. |
| **Student** | Progress | Can successfully view their own `StudentProgress` on the `LearningTrajectory`. |
| **Admin** | Monitoring | `Teacher`s can view `StudentProgress` dashboards. |

### 1.2. Quality & Performance KPIs
These metrics ensure the product is stable, reliable, and provides a good user experience.

| Metric | Target | How Measured |
| :--- | :--- | :--- |
| **Chatbot Faithfulness** | **100%** | All factual answers provided by the bot *must* include at least one accurate `Citation` to the `SourceMaterial`. (Manual & Automated testing) |
| **Chatbot Scoping** | **>99%** | Bot correctly refuses to answer out-of-scope questions in 99/100 test cases. (Automated testing) |
| **Chatbot Latency** | **< 3 seconds** | 95% of all chat responses are delivered to the user in under 3 seconds. (System logs) |
| **Indexing Speed** | **< 5 minutes** | A standard 20-page PDF `SourceMaterial` must transition from `PENDING` to `INDEXED` in under 5 minutes. (System logs) |
| **Page Load Time** | **< 2 seconds** | 95% of all core pages (dashboard, chat, course management) load in under 2 seconds. (Monitoring tools) |

### 1.3. Release Readiness Criteria
These criteria confirm that the product is operationally ready for its target users.

| Category | Criteria | Status (Go/No-Go) |
| :--- | :--- | :--- |
| **Critical Bugs** | **0** | There are zero known P0 (critical, system-crashing, data-loss) bugs. |
| **High-Priority Bugs** | **< 5** | There are fewer than 5 known P1 (high-priority, non-blocking) bugs, and all have documented workarounds. |
| **Adoption Testing** | **3 Courses** | At least 3 full, real-world courses from 3 different `Teacher`s have been successfully uploaded and `Indexed` in the production environment. |
| **User Acceptance** | **Pass** | The product has been demoed to at least 5 target `Student`s and 3 target `Teacher`s (the "Adoption Testing" group), and **no P0/P1 (blocking) issues reported and all critical feedback addressed.** |
| **Documentation** | **Complete** | The `Glossary.md` and `PRD.md` are up-to-date and reflect the released product. |

---

## 2. Detailed Feature Acceptance Criteria

This section provides the specific, testable GIVEN/WHEN/THEN criteria for the features outlined in the [PRD.md](PRD.md).

### 2.1. Epic: Course Content Chatbot (Student-Facing)

#### 2.1.1. Feature: Scoped & Grounded Conversation
* **GIVEN** a `Student` asks a question that is *within* the scope of the `SourceMaterial`...
    * **WHEN** the bot replies...
    * **THEN** the answer MUST be factually correct and derived from the `Knowledge Base`.
* **GIVEN** a `Student` asks a question that is *outside* the scope (e.g., "What's the capital of France?")...
    * **WHEN** the bot replies...
    * **THEN** it MUST politely state that it can only answer questions related to the specific course material.
* **GIVEN** the bot provides any factual answer...
    * **WHEN** the `Student` receives the message...
    * **THEN** the message MUST include one or more `Citations` to the specific `SourceMaterial` (e.g., "See *Lecture 3, Slide 8*").
* **GIVEN** a `Citation` is provided...
    * **WHEN** a `Student` checks it...
    * **THEN** the `MessageCitation` entry in the database MUST be accurate, and the cited source MUST support the answer.

#### 2.1.2. Feature: Socratic Learning Experience
* **GIVEN** a `Student` asks a "how-to-solve" or conceptual question (not a simple fact lookup)...
    * **WHEN** the bot replies...
    * **THEN** its first response MUST be a guiding question, not a direct answer.
* **GIVEN** the bot provides a Socratic response...
    * **WHEN** the `ChatMessage` is logged...
    * **THEN** its `is_socratic` attribute MUST be set to `true`.
* **GGIVEN** a `Student` is struggling with the Socratic dialogue...
    * **WHEN** they ask...
    * **THEN** they MUST have an option to request a direct hint or the final answer.

#### 2.1.3. Feature: Personalized Answers
* **GIVEN** a `Student` has a `StudentProgress` status of `NOT_STARTED` for "Topic A"...
    * **WHEN** they ask about "Topic A"...
    * **THEN** the bot MUST provide a high-level, introductory explanation.
* **GIVEN** a `Student` has a `StudentProgress` status of `IN_PROGRESS` for "Topic A"...
    * **WHEN** they ask about "Topic A"...
    * **THEN** the bot MUST provide a more detailed explanation and offer a practice question.
* **GGIVEN** a `Student` has a `StudentProgress` status of `MASTERED` for "Topic A"...
    * **WHEN** they ask about "Topic A"...
    * **THEN** the bot MAY offer connections to more advanced topics or more complex examples.

#### 2.1.4. Feature: Motivation & Purpose (PRD 4.2)
* **GIVEN** a `Student` asks a "why" question (e.g., "Why is 'Big-O Notation' important?")...
    * **WHEN** the bot replies...
    * **THEN** the answer MUST be derived from the `SourceMaterial` (or a teacher-defined `Topic` description).
* **GIVEN** a `Student` asks a "connection" question (e.g., "What does this depend on?")...
    * **WHEN** the bot replies...
    * **THEN** the answer MUST reference the `LearningTrajectory` (e.g., "This topic builds on 'Data Structures', which you've already mastered.").

### 2.2. Epic: Personalized Assessment (Student-Facing)

#### 2.2.1. Feature: On-Demand Quiz Generation
* **GIVEN** a `Student` navigates to the "Practice Quiz" area...
    * **WHEN** the page loads...
    * **THEN** they MUST be presented with options to filter by:
        * One or more `Topic`(s) from the `LearningTrajectory`.
        * Number of questions.
* **GIVEN** a `Student` generates a quiz...
    * **WHEN** the quiz is presented...
    * **THEN** all questions MUST be relevant to the selected `Topic`(s).
* **GIVEN** a `Student` submits a quiz...
    * **WHEN** the results are shown...
    * **THEN** they MUST receive immediate, question-by-question feedback (correct/incorrect).
    * **AND** for incorrect answers, an explanation and `Citation` to the `SourceMaterial` MUST be provided.
    * **AND** the `StudentProgress` status for the related `Topic`(s) MUST be updated (e.g., to 'IN_PROGRESS' or 'MASTERED' based on score).

### 2.3. Epic: Content Management (Teacher-Facing)

#### 2.3.1. Feature: Course Content Ingestion
* **GIVEN** a `Teacher` is on their "Manage Course" page...
    * **WHEN** the page loads...
    * **THEN** they MUST have an interface to upload new `SourceMaterial` files (e.g., PDF, .md).
* **GIVEN** a `Teacher` uploads a valid file...
    * **WHEN** the upload is complete...
    * **THEN** a `SourceMaterial` entry is created with `indexed_status` = `PENDING`.
    * **AND** the `Indexing` process MUST begin automatically.
* **GIVEN** the `Indexing` process finishes successfully...
    * **WHEN** the `Teacher` views their `SourceMaterial` list...
    * **THEN** the file's `indexed_status` MUST be `INDEXED` (e.g., within 5 minutes for a 20-page PDF).
* **GIVEN** the `Indexing` process fails...
    * **WHEN** the `Teacher` views their `SourceMaterial` list...
    * **THEN** the file's `indexed_status` MUST be `ERROR` and an error message should be available.
* **GIVEN** a `Teacher`...
    * **WHEN** they are on the "Manage Course" page...
    * **THEN** they MUST have an interface to add, view, and remove whitelisted external URLs.
* **GIVEN** a `Teacher` is on their "Manage Course" page...
    * **WHEN** they click "Delete" on a `SourceMaterial` entry...
    * **THEN** they MUST be asked to confirm the deletion.
    * **AND** upon confirmation, the `SourceMaterial` MUST be removed from the `Knowledge Base` and no longer used in answers.

#### 2.3.2. Feature: Content Consistency Review (PRD 4.3)
* **GIVEN** a `Teacher` has successfully indexed all `SourceMaterial` for a course...
    * **WHEN** they navigate to the "Content" page...
    * **THEN** they MUST have an option to "Run Consistency Review".
* **GGIVEN** a `Teacher` has run a consistency review...
    * **WHEN** the review is complete...
    * **THEN** the system MUST present a report flagging potential contradictions (e.g., "Term 'X' is defined differently in *Doc A* and *Doc B*").

### 2.4. Epic: Course & Student Management (Teacher-Facing)

#### 2.4.1. Feature: Learning Trajectory Definition
* **GIVEN** a `Teacher`...
    * **WHEN** they manage their `Course`...
    * **THEN** they MUST have a UI to Create, Read, Update, and Delete `Topic`s for the course.
* **GGIVEN** a `Teacher` has defined `Topic`s...
    * **WHEN** they edit the `LearningTrajectory`...
    * **THEN** they MUST be able to add/remove `Topic`s and define their sequential `order`.

#### 2.4.2. Feature: Student Progress Monitoring
* **GIVEN** a `Teacher`...
    * **WHEN** they view their course dashboard...
    * **THEN** they MUST see a high-level summary of `StudentProgress` for the entire class (e.g., % of students who have 'MASTERED' each `Topic`).
* **GIVEN** a `Teacher`...
    * **WHEN** they are on the dashboard...
    * **THEN** they MUST be able to select an individual `Student` to see their specific `StudentProgress` against the `LearningTrajectory`.

#### 2.4.3. Feature: Assessment Generation
* **GIVEN** a `Teacher`...
    * **WHEN** they choose to create a new `Assessment`...
    * **THEN** they MUST be able to select `Topic`(s), number of questions, and question types.
* **GIVEN** a `Teacher` is generating an `Assessment`...
    * **WHEN** they request it...
    * **THEN** the system MUST provide suggested `LLM-resilient` questions (e.g., scenario-based, multi-step problems) based on the `SourceMaterial`.
* **GIVEN** an `Assessment` is generated...
    * **WHEN** the `Teacher` reviews it...
    * **THEN** they MUST be able to edit, remove, or add questions before saving it.

#### 2.4.4. Feature: Academic Integrity Monitoring (PRD 4.4)
* **GIVEN** a `Teacher` is reviewing student activity...
    * **WHEN** they view an "Integrity Dashboard"...
    * **THEN** the system MUST provide high-level alerts for suspicious patterns (e.g., "Student A has a 95% copy-paste similarity from chatbot to assignment").
* **GIVEN** a `Teacher` is reviewing `ChatSession` logs...
    * **WHEN** they view a conversation...
    * **THEN** text that is identical or highly similar to a submitted `Assessment` MUST be flagged.

---

## 3.0 Out of Scope for MVP

The following features, while part of the long-term vision (from `DraftPRD.md`), are explicitly **OUT OF SCOPE** for the MVP release to ensure a focused and timely delivery of core value.

1.  **Student Tooling & Debug Help:**
    * **Description:** Assisting students with installing tools, debugging compilation errors, or understanding submission procedures.
    * **Reason for Postponing:** This is a very complex, non-trivial feature that requires a different kind of `RAG` and model training. It is secondary to the primary goal of learning course *content*.

2.  **Teacher-Assisted Grading:**
    * **Description:** Tools for `Teacher`s to grade assignments.
    * **Reason for Postponing:** The MVP focuses on *student* practice and *teacher* monitoring. Graded assignments are a separate, complex domain.

3.  **Detailed `LLM-resilient` Verification:**
    * **Description:** Verifying that a `Teacher`-created `Assessment` is "LLM-resilient".
    * **Reason for Postponing:** While we *suggest* questions (2.4.3), actively *verifying* resilience is a complex research problem.